{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "In this notebook we will try to gather as much data as possible concerning our subject XXXXXX\n",
    "\n",
    "To achieve this we will follow this path :\n",
    "\n",
    "1. Scrape ArianeWeb, to retrieve the most important decisions\n",
    "2. Scrape Opendata.justive administrative, to get every other decisions\n",
    "\n",
    "We will later on reconcily those two databases to filter out redundancy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install  and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q pandas bs4 requests selenium regex lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys as KeysBrowser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import regex as re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Scrape ArianeWeb\n",
    "\n",
    "\n",
    "We want first to scrape [ArianeWeb](https://www.conseil-etat.fr/arianeweb/#/recherche) website which provides numerous decisions made by the Conseil d'Etat.\n",
    "\n",
    "More precisely, we found out that it contains following data (*in French*) :\n",
    "\n",
    "\n",
    "**Les décisions et analyses du Conseil d’État, les conclusions des rapporteurs publics**\n",
    "\n",
    "Décisions, avis contentieux et ordonnances rendus depuis le 19 février 1875. En particulier : \n",
    "\n",
    "- 19/02/1875-1965 : décisions fondamentales (Grands arrêts)\n",
    "- 1965-1986 : décisions présentant un intérêt jurisprudentiel (décisions publiées (A) ou mentionnées (B) dans les tables du recueil Lebon et dont les analyses sont disponibles dans Ariane Web\n",
    "- Depuis 1987 : toutes les décisions, sauf celles statuant sur l’admission de pourvois en cassation et les ordonnances usuelles des présidents\n",
    "- Analyses de décisions collégiales, avis contentieux et ordonnances de référé publiés (A) ou mentionnés (B) dans les tables du recueil Lebon, depuis le 19 février 1875\n",
    "- Sélection des conclusions des rapporteurs publics : conclusions relatives à des décisions collégiales et avis contentieux depuis le 31 janvier 2007\n",
    "\n",
    "(*[source](https://jurisguide.fr/fiches-documentaires/arianeweb-1/)*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get Ariane landing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we instantiate the webdriver\n",
    "driver = webdriver.Chrome() \n",
    "\n",
    "# we get the page thanks to its url\n",
    "url = \"https://www.conseil-etat.fr/arianeweb/#/recherche\"\n",
    "\n",
    "# at this point drivers lands in the home page of the website\n",
    "driver.get(url)\n",
    "\n",
    "# we inspect the .html page and find the path to \"Décisions du conseil d'etat\" and \"Rechercher\" buttons\n",
    "x_path_decisions = \"/html/body/div[2]/div[2]/div[1]/form/div[2]/div/div[1]/div[1]/label/input\"\n",
    "x_path_rechercher = \"/html/body/div[2]/div[2]/div[1]/form/div[4]/div/button\"\n",
    "\n",
    "# we click on the \"Décisions du conseil d'etat\" checkbox to get only the decisions \n",
    "driver.find_element(By.XPATH, x_path_decisions).click()\n",
    "\n",
    "# we click on the \"Rechercher\" button to get the results\n",
    "driver.find_element(By.XPATH, x_path_rechercher).click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Test to parse a single decision\n",
    "\n",
    "We saved a single decision page as an html file and try to parse it to decide what we want to keep.\n",
    "\n",
    "Post discussion with our team we agreed on keeping :\n",
    "\n",
    "- date of the decision\n",
    "- decision id\n",
    "- composition of the counsel\n",
    "- corpus\n",
    "- decision\n",
    "\n",
    "We will later define what kind of decisions are interesting for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.139)\nStacktrace:\n0   chromedriver                        0x00000001009b27dc chromedriver + 4040668\n1   chromedriver                        0x00000001009aa9e0 chromedriver + 4008416\n2   chromedriver                        0x000000010061d870 chromedriver + 284784\n3   chromedriver                        0x00000001005f8064 chromedriver + 131172\n4   chromedriver                        0x00000001006872b0 chromedriver + 717488\n5   chromedriver                        0x000000010069a75c chromedriver + 796508\n6   chromedriver                        0x000000010065574c chromedriver + 513868\n7   chromedriver                        0x0000000100656044 chromedriver + 516164\n8   chromedriver                        0x0000000100977a04 chromedriver + 3799556\n9   chromedriver                        0x000000010097bee4 chromedriver + 3817188\n10  chromedriver                        0x0000000100960260 chromedriver + 3703392\n11  chromedriver                        0x000000010097ca2c chromedriver + 3820076\n12  chromedriver                        0x000000010095301c chromedriver + 3649564\n13  chromedriver                        0x0000000100999e3c chromedriver + 3939900\n14  chromedriver                        0x0000000100999fb4 chromedriver + 3940276\n15  chromedriver                        0x00000001009aa660 chromedriver + 4007520\n16  libsystem_pthread.dylib             0x000000019b633fa8 _pthread_start + 148\n17  libsystem_pthread.dylib             0x000000019b62eda0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m x_path_date_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/strong[3]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# load page in driver\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile:/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhtml_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# get the date and id of the decision\u001b[39;00m\n\u001b[1;32m     11\u001b[0m date_id \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, x_path_date_id)\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/Documents/legal_analysis/venv_legal/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/legal_analysis/venv_legal/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/legal_analysis/venv_legal/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=121.0.6167.139)\nStacktrace:\n0   chromedriver                        0x00000001009b27dc chromedriver + 4040668\n1   chromedriver                        0x00000001009aa9e0 chromedriver + 4008416\n2   chromedriver                        0x000000010061d870 chromedriver + 284784\n3   chromedriver                        0x00000001005f8064 chromedriver + 131172\n4   chromedriver                        0x00000001006872b0 chromedriver + 717488\n5   chromedriver                        0x000000010069a75c chromedriver + 796508\n6   chromedriver                        0x000000010065574c chromedriver + 513868\n7   chromedriver                        0x0000000100656044 chromedriver + 516164\n8   chromedriver                        0x0000000100977a04 chromedriver + 3799556\n9   chromedriver                        0x000000010097bee4 chromedriver + 3817188\n10  chromedriver                        0x0000000100960260 chromedriver + 3703392\n11  chromedriver                        0x000000010097ca2c chromedriver + 3820076\n12  chromedriver                        0x000000010095301c chromedriver + 3649564\n13  chromedriver                        0x0000000100999e3c chromedriver + 3939900\n14  chromedriver                        0x0000000100999fb4 chromedriver + 3940276\n15  chromedriver                        0x00000001009aa660 chromedriver + 4007520\n16  libsystem_pthread.dylib             0x000000019b633fa8 _pthread_start + 148\n17  libsystem_pthread.dylib             0x000000019b62eda0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "# path to the decision we want to parse\n",
    "html_path = \"../data/487634.html\"\n",
    "\n",
    "# path to the line with date and id of the decision\n",
    "x_path_date_id = \"/html/body/strong[3]\"\n",
    "\n",
    "# load page in driver\n",
    "driver.get(\"file:/\" + html_path)\n",
    "\n",
    "# get the date and id of the decision\n",
    "date_id = driver.find_element(By.XPATH, x_path_date_id).text\n",
    "\n",
    "date_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Test to scrape the first page\n",
    "\n",
    "We'll check if we can get the result for a single page before trying to retrieve all the results.\n",
    "\n",
    "For improved readibility and fanciness we will use a function that parses a page's html.\n",
    "\n",
    "This function is mainly inspired by Prof Charlotin's code snippet provided in Notebook #3 : Scraping \n",
    "\n",
    "(honesty would force us to confess that it is a 100% copy-paste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_decision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         driver\u001b[38;5;241m.\u001b[39mswitch_to\u001b[38;5;241m.\u001b[39mwindow(driver\u001b[38;5;241m.\u001b[39mwindow_handles[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# Important to return to main window, or the next search for rowel won't work\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mparse_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# We call the function with the current page (first one)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m, in \u001b[0;36mparse_page\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_page\u001b[39m(soup):\n\u001b[0;32m----> 5\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Collect tables from the page; there are two of them\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# in the page source (and find_all returns a list), and we are interested in the last one.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(\u001b[38;5;28mstr\u001b[39m(table))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# To make things easier, we convert the table in a panda\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# the functions takes the whole html page stored as a soup and parses it \n",
    "\n",
    "def parse_page(soup):\n",
    "\n",
    "    table = soup.find_all(\"table\")[-1]  # Collect tables from the page; there are two of them\n",
    "# in the page source (and find_all returns a list), and we are interested in the last one.\n",
    "\n",
    "    df = pd.read_html(str(table))[-1]  # To make things easier, we convert the table in a panda\n",
    "    # dataframe \n",
    "\n",
    "    for index, row in df.iterrows():  # For each row, we'll make the browser click on the element\n",
    "        # and collect the judgment\n",
    "        num = re.search(r\"\\d+\", row[\"Numéro d'affaire\"]).group()  # Taking only the number because\n",
    "        # the (...) messes up xPath\n",
    "        row_el = driver.find_element(By.XPATH, \".//td[contains(text(), '\" + num + \"')]\")\n",
    "        # With that num, we look for the relevant element in browser\n",
    "        row_el.click()  # load page with judgment\n",
    "        time.sleep(1)  # Giving the page time (2s) to load before changing focus with function\n",
    "        # time.sleep (imported above)\n",
    "        driver.switch_to.window(driver.window_handles[-1])\n",
    "        ## Switch the driver's focus to the window you just opened, with method \"switch to\",\n",
    "        # and argument the relevant window from the list of window_handles\n",
    "        # (latest loaded window will be -1)\n",
    "\n",
    "\n",
    "\n",
    "       ##########\n",
    "        a change ici\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ave_el = driver.find_element(By.CSS_SELECTOR, \"button[title='enregistre le document']\")\n",
    "        # Find the download button, using CSS selector here so as to rely on the unique 'title'\n",
    "        ave_el.click()  # Downloading the judgment, in html format; it will end up in\n",
    "        # your normal Download folder\n",
    "\n",
    "        # we add a time.sleep to let the file download\n",
    "        time.sleep(1)\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "        # Important to return to main window, or the next search for rowel won't work\n",
    "\n",
    "parse_page(BeautifulSoup(driver.page_source, \"html.parser\")) # We call the function with the current page (first one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Test to keep only interesting pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Final parsing\n",
    "\n",
    "As from now (07/02), the above request outputs 3190 pages. \n",
    "This parameter can be easily changed by attributing a new value to the 'num_page' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pages = 3190 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_legal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
